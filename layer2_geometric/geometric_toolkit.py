"""
geometric_toolkit
=================

E8 Lattice operations, Weyl chambers, Cartan matrices

Auto-generated by CQE Builder
"""
from pathlib import Path


# Standard library imports
from dataclasses import dataclass
from dataclasses import dataclass, asdict
from enum import Enum
from typing import Dict, List, Tuple, Optional, Any, Union
from typing import List, Tuple
from typing import List, Tuple, Dict
from typing import List, Tuple, Dict, Any, Optional, Callable
import hashlib
import json
import json, math, argparse, sys
import json, time, math, random, argparse, sys, hashlib, os
import math
import sys


# ============================================================# MODULE: LatticeBuilderV1 (from code_monolith.py)# ============================================================


#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Lattice Builder & Validator v1 (pure stdlib)
--------------------------------------------
- Build Gram matrices for ADE root lattices (A_n, D_n, E6/7/8) and direct sums.
- Validate integrality, evenness, determinant, unimodularity.
- Enumerate short vectors via branch-and-bound (Cholesky) to detect roots (||v||^2=2).
- Niemeier helper: recognize candidate root systems by spec; Leech check (rootless + even unimodular in 24D).

This is a math validator: it does *not* attempt full glue-code overlattice construction.
"""
import json, math, argparse, sys
from typing import List, Tuple, Dict

# ──────────────────────────────────────────────────────────────────────────────
# Utilities
# ──────────────────────────────────────────────────────────────────────────────

Matrix = List[List[float]]
Vector = List[float]

def mat_det(A: Matrix) -> float:
    n = len(A)
    M = [row[:] for row in A]
    det = 1.0
    for i in range(n):
        # pivot
        piv = i
        for r in range(i, n):
            if abs(M[r][i]) > abs(M[piv][i]): piv = r
        if abs(M[piv][i]) < 1e-12: return 0.0
        if piv != i:
            M[i], M[piv] = M[piv], M[i]; det *= -1
        det *= M[i][i]
        pivval = M[i][i]
        for j in range(i+1, n):
            fac = M[j][i] / pivval
            if fac == 0: continue
            for k in range(i, n):
                M[j][k] -= fac * M[i][k]
    return det

def is_integral(A: Matrix) -> bool:
    for i in range(len(A)):
        for j in range(len(A)):
            if abs(A[i][j] - round(A[i][j])) > 1e-10:
                return False
    return True

def is_even(A: Matrix) -> bool:
    # even lattice means x·x ∈ 2Z for all x; for root-lattice Gram (Cartan) this reduces to diag even
    return all(int(round(A[i][i])) % 2 == 0 for i in range(len(A)))

def cholesky(A: Matrix) -> Matrix:
    n = len(A)
    L = [[0.0]*n for _ in range(n)]
    for i in range(n):
        for j in range(i+1):
            s = sum(L[i][k]*L[j][k] for k in range(j))
            if i == j:
                v = A[i][i] - s
                if v <= 0: raise ValueError("Matrix not positive definite")
                L[i][j] = math.sqrt(v)
            else:
                L[i][j] = (A[i][j] - s) / L[j][j]
    return L

def quad_norm(G: Matrix, x: Vector) -> float:
    # x^T G x
    n = len(G)
    s = 0.0
    for i in range(n):
        for j in range(n):
            s += x[i]*G[i][j]*x[j]
    return s

# ──────────────────────────────────────────────────────────────────────────────
# ADE root-lattice builders via Cartan matrices
# ──────────────────────────────────────────────────────────────────────────────

def cartan_A(n: int) -> Matrix:
    A = [[0]*n for _ in range(n)]
    for i in range(n):
        A[i][i] = 2
        if i>0: A[i][i-1] = -1
        if i<n-1: A[i][i+1] = -1
    return [list(map(float, r)) for r in A]

def cartan_D(n: int) -> Matrix:
    # D_n: chain with a fork at node n-2
    A = [[0]*n for _ in range(n)]
    for i in range(n):
        A[i][i] = 2
    for i in range(n-2):
        A[i][i+1] = A[i+1][i] = -1
    A[n-3][n-1] = A[n-1][n-3] = -1
    return [list(map(float, r)) for r in A]

def cartan_E6() -> Matrix:
    # numbering: chain 1-2-3-4-5 with 3 connected to 6
    A = [[2, -1, 0, 0, 0, 0],
         [-1, 2, -1, 0, 0, 0],
         [0, -1, 2, -1, 0, -1],
         [0, 0, -1, 2, -1, 0],
         [0, 0, 0, -1, 2, 0],
         [0, 0, -1, 0, 0, 2]]
    return [list(map(float, r)) for r in A]

def cartan_E7() -> Matrix:
    # chain 1-2-3-4-5-6 with 3 connected up to 7
    A = [[2, -1, 0, 0, 0, 0, 0],
         [-1, 2, -1, 0, 0, 0, 0],
         [0, -1, 2, -1, 0, 0, -1],
         [0, 0, -1, 2, -1, 0, 0],
         [0, 0, 0, -1, 2, -1, 0],
         [0, 0, 0, 0, -1, 2, 0],
         [0, 0, -1, 0, 0, 0, 2]]
    return [list(map(float, r)) for r in A]

def cartan_E8() -> Matrix:
    # chain 1-2-3-4-5-6-7 with 3 connected up to 8
    A = [[2, -1, 0, 0, 0, 0, 0, 0],
         [-1, 2, -1, 0, 0, 0, 0, 0],
         [0, -1, 2, -1, 0, 0, 0, -1],
         [0, 0, -1, 2, -1, 0, 0, 0],
         [0, 0, 0, -1, 2, -1, 0, 0],
         [0, 0, 0, 0, -1, 2, -1, 0],
         [0, 0, 0, 0, 0, -1, 2, 0],
         [0, 0, -1, 0, 0, 0, 0, 2]]
    return [list(map(float, r)) for r in A]

def block_diag(blocks: List[Matrix]) -> Matrix:
    n = sum(len(b) for b in blocks)
    M = [[0.0]*n for _ in range(n)]
    o = 0
    for B in blocks:
        m = len(B)
        for i in range(m):
            for j in range(m):
                M[o+i][o+j] = B[i][j]
        o += m
    return M

def parse_root_spec(spec: str) -> Matrix:
    """"""
    tokens = spec.replace('*','^').replace('+',' ').replace(',',' ').split()
    blocks: List[Matrix] = []
    for tok in tokens:
        if '^' in tok:
            base, times = tok.split('^', 1)
            times = int(times)
        else:
            base, times = tok, 1
        base = base.strip().upper()
        for _ in range(times):
            if base.startswith('A'):
                n = int(base[1:])
                blocks.append(cartan_A(n))
            elif base.startswith('D'):
                n = int(base[1:])
                blocks.append(cartan_D(n))
            elif base == 'E6':
                blocks.append(cartan_E6())
            elif base == 'E7':
                blocks.append(cartan_E7())
            elif base == 'E8':
                blocks.append(cartan_E8())
            else:
                raise ValueError(f"Unknown base '{base}' in spec")
    return block_diag(blocks)

# ──────────────────────────────────────────────────────────────────────────────
# Enumeration of short vectors (Fincke–Pohst style, very small radius)
# ──────────────────────────────────────────────────────────────────────────────

def enumerate_short(G: Matrix, R2: float=2.0, limit: int=100000) -> List[Vector]:
    """
    Warning: exponential in rank; good for small ranks or small R2.
"""
    n = len(G)
    L = cholesky(G)  # G = L L^T
    sol: List[Vector] = []
    x = [0]*n
    # Precompute for pruning: partial norms using L
    # We'll search in reverse order
    bounds = [0]*n
    def rec(k: int, residual: float):
        nonlocal sol, x
        if k < 0:
            if any(xi!=0 for xi in x):
                sol.append(x[:])
            return
        # compute bound on x_k from residual
        Lkk = L[k][k]
        max_abs = int(math.floor(math.sqrt(max(0.0, residual))/Lkk + 1e-9))
        for t in range(-max_abs, max_abs+1):
            # update residual: || L^T x ||^2 <= R2
            # compute contribution at level k
            s = t * L[k][k]
            for j in range(k+1, n):
                s += x[j]*L[j][k]
            new_res = residual - s*s
            if new_res >= -1e-12:
                x[k] = t
                rec(k-1, new_res)
                if len(sol) >= limit: return
        x[k] = 0
    rec(n-1, R2)
    return sol

def has_root(G: Matrix) -> bool:
    # root = vector of squared length 2 in root lattice basis
    sols = enumerate_short(G, R2=2.0, limit=100000)
    for v in sols:
        q = quad_norm(G, v)
        if abs(q-2.0) < 1e-9:
            return True
    return False

# ──────────────────────────────────────────────────────────────────────────────
# Niemeier helpers
# ──────────────────────────────────────────────────────────────────────────────

NIEMEIER_ROOT_SPECS = [
    "D24", "D16 E8", "E8^3", "A24", "D12^2", "A17 E7", "D10 E7^2",
    "A15 D9", "D8^3", "A12^2", "A11 D7 E6", "E6^4", "A9^2 D6",
    "D6^4", "A8^3", "A7^2 D5^2", "A6^4", "A5^4 D4", "D4^6",
    "A4^6", "A3^8", "A2^12", "A1^24"
]
# Leech is the unique even unimodular rank-24 lattice with no roots.

def validate_properties(G: Matrix) -> Dict:
    d = mat_det(G)
    return {
        "rank": len(G),
        "det": d,
        "integral": is_integral(G),
        "even": is_even(G),
        "unimodular": abs(round(d)-1)==1 and abs(d-1.0) < 1e-8
    }

def niemeier_check(G: Matrix) -> Dict:
    props = validate_properties(G)
    report = {"props": props, "rank": len(G)}
    if len(G) != 24:
        report["niemeier_candidate"] = False
        return report
    if props["even"] and props["unimodular"]:
        # Try to detect roots quickly
        root_present = has_root(G)
        report["root_present"] = root_present
        if not root_present:
            report["classification"] = "Leech (unique even unimodular rank-24 rootless lattice)"
        else:
            report["classification"] = "Even unimodular rank-24 with roots (some Niemeier overlattice)"
        report["niemeier_candidate"] = True
    else:
        report["niemeier_candidate"] = False
    return report

# ──────────────────────────────────────────────────────────────────────────────
# CLI
# ──────────────────────────────────────────────────────────────────────────────

def main(argv=None):
    p = argparse.ArgumentParser()
    sub = p.add_subparsers(dest="cmd")
    b = sub.add_parser("build"); b.add_argument("spec", help="e.g. 'E8^3' or 'A8 + D16'"); b.add_argument("--out", default=None)
    v = sub.add_parser("validate"); v.add_argument("--gram-json", required=True)
    r = sub.add_parser("roots"); r.add_argument("--gram-json", required=True); r.add_argument("--bound", type=float, default=2.0)
    n = sub.add_parser("niemeier"); n.add_argument("--gram-json", required=True)

    args = p.parse_args(argv)

    if args.cmd == "build":
        G = parse_root_spec(args.spec)
        out = json.dumps(G)
        if args.out:
            open(args.out, "w").write(out)
            print(json.dumps({"wrote": args.out, "rank": len(G)}))
        else:
            print(out)
        return

    if args.cmd == "validate":
        G = json.load(open(args.gram_json))
        print(json.dumps(validate_properties(G), indent=2))
        return

    if args.cmd == "roots":
        G = json.load(open(args.gram_json))
        sols = enumerate_short(G, R2=args.bound)
        cnt2 = sum(1 for v in sols if abs(quad_norm(G, v)-2.0) < 1e-9)
        print(json.dumps({"enumerated": len(sols), "roots_of_norm2_found": cnt2}, indent=2))
        return

    if args.cmd == "niemeier":
        G = json.load(open(args.gram_json))
        print(json.dumps(niemeier_check(G), indent=2))
        return

    p.print_help()

if __name__ == "__main__":
    main()


# ============================================================# MODULE: GeometryBridge (from code_monolith.py)# ============================================================


from typing import List, Tuple
import math

Vec = Tuple[float, float]

def centroid(ps: List[Vec]) -> Vec:
    n = max(1, len(ps))
    return (sum(p[0] for p in ps)/n, sum(p[1] for p in ps)/n)

def v_sub(a: Vec, b: Vec) -> Vec: return (a[0]-b[0], a[1]-b[1])
def v_norm(a: Vec) -> float: return math.hypot(a[0], a[1])
def angle(a: Vec) -> float: return math.atan2(a[1], a[0])

def radial_angle_hist(pts: List[Vec], rbins=16, abins=16) -> list:
    if not pts: return [0.0]*(rbins+abins+4)
    c = centroid(pts)
    rs, ths = [], []
    for p in pts:
        d = v_sub(p, c)
        rs.append(v_norm(d))
        ths.append((angle(d)%(2*math.pi)))
    R = max(1e-9, max(rs))
    rh = [0]*rbins; ah = [0]*abins
    for r, th in zip(rs, ths):
        ri = min(rbins-1, int(rbins * (r / R)))
        ai = min(abins-1, int(abins * (th /(2*math.pi))))
        rh[ri] += 1; ah[ai] += 1
    rh = [x/len(pts) for x in rh]
    ah = [x/len(pts) for x in ah]
    return rh + ah + [float(len(pts)), R, sum(rs)/len(rs), 0.0]


# ============================================================# MODULE: E8Bridge (from code_monolith.py)# ============================================================

#!/usr/bin/env python3.11
"""
Extended Lambda Calculus (Λ⊗E8)
================================

Lambda calculus extended to capture geometric transforms in E8 space.
Integrates with:
- Geometric Transformer (captures transform operations as lambda)
- Token Object System (lambda IR in tokens)
- AGRM/MDHG (path operations as lambda composition)

Key features:
- Geometric operations as lambda terms
- E8 lattice navigation as lambda composition
- Dihedral operations as lambda transformations
- Automatic derivation from system operations
- Type system for geometric constraints
"""

import sys
sys.path.insert(0, str(Path(__file__).resolve().parent.parent))

from typing import Dict, List, Tuple, Optional, Any, Union
from dataclasses import dataclass
from enum import Enum
import hashlib
import json

# ============================================================================
# LAMBDA TERM TYPES
# ============================================================================

class LambdaType(Enum):
    """"""
    SCALAR = "scalar"           # Real number
    VECTOR = "vector"           # E8 vector
    LATTICE = "lattice"         # E8 lattice point
    TRANSFORM = "transform"     # Geometric transform
    PATH = "path"               # AGRM path
    TOKEN = "token"             # Token Object
    DIHEDRAL = "dihedral"       # Dihedral group element

@dataclass
class LambdaTerm:
    """
    A term in the extended lambda calculus.
    
    Grammar:
        t ::= x                     (variable)
            | λ x: τ. t            (abstraction)
            | t t                   (application)
            | (e8_embed t)          (E8 embedding)
            | (e8_project t d)      (E8 projection to dimension d)
            | (e8_navigate t w)     (Navigate E8 via Weyl chamber w)
            | (dihedral_op N k t)   (Dihedral operation)
            | (path_compose t1 t2)  (AGRM path composition)
            | (conserve t)          (Apply conservation law)
    """
    term_type: str  # "var", "abs", "app", "e8_op", "dihedral_op", "path_op"
    content: Any    # Depends on term_type
    lambda_type: Optional[LambdaType] = None
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}
    
    def to_string(self) -> str:
        """"""
        if self.term_type == "var":
            return self.content
        
        elif self.term_type == "abs":
            var, body = self.content
            type_annotation = f": {self.lambda_type.value}" if self.lambda_type else ""
            return f"(λ {var}{type_annotation}. {body.to_string()})"
        
        elif self.term_type == "app":
            func, arg = self.content
            return f"({func.to_string()} {arg.to_string()})"
        
        elif self.term_type == "e8_op":
            op_name, args = self.content
            arg_strs = [a.to_string() if isinstance(a, LambdaTerm) else str(a) for a in args]
            return f"({op_name} {' '.join(arg_strs)})"
        
        elif self.term_type == "dihedral_op":
            N, k, reflect, arg = self.content
            return f"(D_{N}^{k}{'*' if reflect else ''} {arg.to_string()})"
        
        elif self.term_type == "path_op":
            op_name, paths = self.content
            path_strs = [p.to_string() if isinstance(p, LambdaTerm) else str(p) for p in paths]
            return f"({op_name} {' '.join(path_strs)})"
        
        else:
            return f"<{self.term_type}>"

# ============================================================================
# LAMBDA CALCULUS BUILDER
# ============================================================================

class LambdaE8Builder:
    """
    Builder for extended lambda calculus terms.
    
    Provides high-level API for constructing lambda terms from
    geometric operations.
    """
    
    def __init__(self):
        self.term_counter = 0
        self.environment: Dict[str, LambdaTerm] = {}
    
    def fresh_var(self, prefix: str = "x") -> str:
        """"""
        self.term_counter += 1
        return f"{prefix}{self.term_counter}"
    
    def var(self, name: str, lambda_type: Optional[LambdaType] = None) -> LambdaTerm:
        """"""
        return LambdaTerm("var", name, lambda_type)
    
    def abs(self, var: str, body: LambdaTerm, lambda_type: Optional[LambdaType] = None) -> LambdaTerm:
        """"""
        return LambdaTerm("abs", (var, body), lambda_type)
    
    def app(self, func: LambdaTerm, arg: LambdaTerm) -> LambdaTerm:
        """"""
        return LambdaTerm("app", (func, arg))
    
    def e8_embed(self, term: LambdaTerm) -> LambdaTerm:
        """"""
        return LambdaTerm("e8_op", ("e8_embed", [term]), LambdaType.LATTICE)
    
    def e8_project(self, term: LambdaTerm, target_dim: int) -> LambdaTerm:
        """"""
        return LambdaTerm("e8_op", ("e8_project", [term, target_dim]), LambdaType.VECTOR)
    
    def e8_navigate(self, term: LambdaTerm, weyl_chamber: int) -> LambdaTerm:
        """"""
        return LambdaTerm("e8_op", ("e8_navigate", [term, weyl_chamber]), LambdaType.LATTICE)
    
    def dihedral(self, N: int, k: int, reflect: bool, term: LambdaTerm) -> LambdaTerm:
        """"""
        return LambdaTerm("dihedral_op", (N, k, reflect, term), LambdaType.DIHEDRAL)
    
    def path_compose(self, path1: LambdaTerm, path2: LambdaTerm) -> LambdaTerm:
        """"""
        return LambdaTerm("path_op", ("path_compose", [path1, path2]), LambdaType.PATH)
    
    def conserve(self, term: LambdaTerm) -> LambdaTerm:
        """"""
        return LambdaTerm("e8_op", ("conserve", [term]), term.lambda_type)
    
    def compose(self, *terms: LambdaTerm) -> LambdaTerm:
        """"""
        if not terms:
            # Identity function
            x = self.fresh_var()
            return self.abs(x, self.var(x))
        
        if len(terms) == 1:
            return terms[0]
        
        # Build composition: (f ∘ g)(x) = f(g(x))
        result = terms[-1]
        for term in reversed(terms[:-1]):
            x = self.fresh_var()
            result = self.abs(
                x,
                self.app(term, self.app(result, self.var(x)))
            )
        
        return result

# ============================================================================
# GEOMETRIC OPERATION CAPTURE
# ============================================================================

class GeometricLambdaCapture:
    """
    Captures geometric operations and converts them to lambda calculus.
    
    Integrates with:
    - Geometric Transformer (attention, feedforward, etc.)
    - Token Object System (tokenization operations)
    - AGRM/MDHG (path operations)
    """
    
    def __init__(self):
        self.builder = LambdaE8Builder()
        self.operation_log: List[Tuple[str, LambdaTerm]] = []
    
    def capture_attention(
        self,
        query_dim: int,
        key_dim: int,
        value_dim: int,
        num_heads: int
    ) -> LambdaTerm:
        """
        Capture attention operation as lambda term.
        
        Attention(Q, K, V) = softmax(Q·K^T / √d) · V
        
        In lambda calculus:
        λ Q. λ K. λ V. (e8_project (softmax (scale (dot Q (transpose K)))) value_dim) · V
        """
        Q = self.builder.var("Q", LambdaType.VECTOR)
        K = self.builder.var("K", LambdaType.VECTOR)
        V = self.builder.var("V", LambdaType.VECTOR)
        
        # Q · K^T
        dot_product = LambdaTerm("e8_op", ("dot", [Q, LambdaTerm("e8_op", ("transpose", [K]))]))
        
        # Scale by √d
        scaled = LambdaTerm("e8_op", ("scale", [dot_product, 1.0 / (key_dim ** 0.5)]))
        
        # Softmax
        attention_weights = LambdaTerm("e8_op", ("softmax", [scaled]))
        
        # Apply to values
        output = LambdaTerm("e8_op", ("dot", [attention_weights, V]))
        
        # Build lambda abstraction
        lambda_term = self.builder.abs("Q",
            self.builder.abs("K",
                self.builder.abs("V", output, LambdaType.VECTOR),
                LambdaType.VECTOR),
            LambdaType.VECTOR)
        
        self.operation_log.append(("attention", lambda_term))
        return lambda_term
    
    def capture_feedforward(
        self,
        input_dim: int,
        hidden_dim: int,
        output_dim: int
    ) -> LambdaTerm:
        """
        Capture feedforward network as lambda term.
        
        FFN(x) = W2 · gelu(W1 · x)
        
        In lambda calculus:
        λ x. (e8_project (gelu (e8_project x hidden_dim)) output_dim)
        """
        x = self.builder.var("x", LambdaType.VECTOR)
        
        # W1 · x (project to hidden)
        hidden = self.builder.e8_project(x, hidden_dim)
        
        # gelu activation
        activated = LambdaTerm("e8_op", ("gelu", [hidden]))
        
        # W2 · h (project to output)
        output = self.builder.e8_project(activated, output_dim)
        
        lambda_term = self.builder.abs("x", output, LambdaType.VECTOR)
        
        self.operation_log.append(("feedforward", lambda_term))
        return lambda_term
    
    def capture_layer_norm(self, dim: int) -> LambdaTerm:
        """
        Capture layer normalization as lambda term.
        
        LayerNorm(x) = (x - μ) / σ
        
        In lambda calculus:
        λ x. (e8_op normalize x)
        """
        x = self.builder.var("x", LambdaType.VECTOR)
        normalized = LambdaTerm("e8_op", ("normalize", [x]))
        
        lambda_term = self.builder.abs("x", normalized, LambdaType.VECTOR)
        
        self.operation_log.append(("layer_norm", lambda_term))
        return lambda_term
    
    def capture_tokenization(
        self,
        surface: str,
        embedding_dim: int
    ) -> LambdaTerm:
        """
        Capture tokenization as lambda term.
        
        Tokenize(text) = embed_e8(text, dim)
        
        In lambda calculus:
        λ text. (e8_embed (lookup text vocab) dim)
        """
        text = self.builder.var("text", LambdaType.SCALAR)
        
        # Lookup in vocabulary
        token_id = LambdaTerm("e8_op", ("lookup", [text, "vocab"]))
        
        # Embed in E8
        embedded = self.builder.e8_embed(token_id)
        
        # Project to target dimension
        projected = self.builder.e8_project(embedded, embedding_dim)
        
        lambda_term = self.builder.abs("text", projected, LambdaType.TOKEN)
        
        self.operation_log.append(("tokenization", lambda_term))
        return lambda_term
    
    def capture_agrm_path(
        self,
        start_node: str,
        end_node: str,
        path_nodes: List[str]
    ) -> LambdaTerm:
        """
        Capture AGRM path as lambda term.
        
        Path(start, end) = compose(edge1, edge2, ..., edgeₙ)
        
        In lambda calculus:
        λ start. λ end. (path_compose edge1 (path_compose edge2 ... edgeₙ))
        """
        # Create edge terms
        edges = []
        for i in range(len(path_nodes) - 1):
            edge = LambdaTerm("path_op", ("edge", [path_nodes[i], path_nodes[i+1]]), LambdaType.PATH)
            edges.append(edge)
        
        # Compose edges
        if not edges:
            # Empty path (identity)
            path_term = LambdaTerm("path_op", ("identity", []), LambdaType.PATH)
        else:
            path_term = edges[0]
            for edge in edges[1:]:
                path_term = self.builder.path_compose(path_term, edge)
        
        # Build lambda abstraction
        lambda_term = self.builder.abs("start",
            self.builder.abs("end", path_term, LambdaType.PATH),
            LambdaType.PATH)
        
        self.operation_log.append(("agrm_path", lambda_term))
        return lambda_term
    
    def capture_dihedral_transform(
        self,
        N: int,
        k: int,
        reflect: bool
    ) -> LambdaTerm:
        """
        Capture dihedral group operation as lambda term.
        
        D_N^k(x) = rotate(x, 2πk/N) [with optional reflection]
        
        In lambda calculus:
        λ x. (D_N^k x)
        """
        x = self.builder.var("x", LambdaType.VECTOR)
        transformed = self.builder.dihedral(N, k, reflect, x)
        
        lambda_term = self.builder.abs("x", transformed, LambdaType.DIHEDRAL)
        
        self.operation_log.append(("dihedral", lambda_term))
        return lambda_term
    
    def get_composed_lambda(self) -> LambdaTerm:
        """"""
        if not self.operation_log:
            return self.builder.abs("x", self.builder.var("x"))
        
        terms = [term for _, term in self.operation_log]
        return self.builder.compose(*terms)
    
    def export_log(self, filepath: str):
        """"""
        log_data = [
            {
                "operation": op_name,
                "lambda_term": term.to_string(),
                "type": term.lambda_type.value if term.lambda_type else None
            }
            for op_name, term in self.operation_log
        ]
        
        with open(filepath, 'w') as f:
            json.dump(log_data, f, indent=2)
        
        print(f"Exported {len(log_data)} lambda operations to {filepath}")

# ============================================================================
# LAMBDA CALCULUS EVALUATOR
# ============================================================================

class LambdaE8Evaluator:
    """
    Evaluator for extended lambda calculus.
    
    Performs beta-reduction and geometric operations.
    """
    
    def __init__(self):
        self.reduction_steps = 0
        self.max_steps = 1000
    
    def evaluate(self, term: LambdaTerm, env: Dict[str, Any] = None) -> Any:
        """
        Evaluate a lambda term.
        
        Args:
            term: Lambda term to evaluate
            env: Environment mapping variables to values
            
        Returns:
            Evaluated result
        """
        if env is None:
            env = {}
        
        self.reduction_steps = 0
        return self._eval(term, env)
    
    def _eval(self, term: LambdaTerm, env: Dict[str, Any]) -> Any:
        """"""
        self.reduction_steps += 1
        
        if self.reduction_steps > self.max_steps:
            raise RuntimeError("Maximum reduction steps exceeded")
        
        if term.term_type == "var":
            return env.get(term.content, term.content)
        
        elif term.term_type == "abs":
            # Return closure
            return ("closure", term, env.copy())
        
        elif term.term_type == "app":
            func, arg = term.content
            func_val = self._eval(func, env)
            arg_val = self._eval(arg, env)
            
            if isinstance(func_val, tuple) and func_val[0] == "closure":
                _, abs_term, closure_env = func_val
                var, body = abs_term.content
                new_env = closure_env.copy()
                new_env[var] = arg_val
                return self._eval(body, new_env)
            else:
                return ("app", func_val, arg_val)
        
        elif term.term_type == "e8_op":
            op_name, args = term.content
            eval_args = [self._eval(a, env) if isinstance(a, LambdaTerm) else a for a in args]
            return (f"e8_{op_name}", *eval_args)
        
        elif term.term_type == "dihedral_op":
            N, k, reflect, arg = term.content
            eval_arg = self._eval(arg, env)
            return ("dihedral", N, k, reflect, eval_arg)
        
        elif term.term_type == "path_op":
            op_name, paths = term.content
            eval_paths = [self._eval(p, env) if isinstance(p, LambdaTerm) else p for p in paths]
            return (f"path_{op_name}", *eval_paths)
        
        else:
            return term

# ============================================================================
# DEMO
# ============================================================================

def demo_lambda_e8_calculus():
    """"""
    print("="*70)
    print("EXTENDED LAMBDA CALCULUS (Λ⊗E8) DEMO")
    print("="*70)
    
    capture = GeometricLambdaCapture()
    
    # Capture various operations
    print("\\n[1] Capturing geometric operations...")
    
    attention = capture.capture_attention(1024, 1024, 1024, 16)
    print(f"\\nAttention: {attention.to_string()}")
    
    ffn = capture.capture_feedforward(1024, 4096, 1024)
    print(f"\\nFeedforward: {ffn.to_string()}")
    
    norm = capture.capture_layer_norm(1024)
    print(f"\\nLayer Norm: {norm.to_string()}")
    
    tokenize = capture.capture_tokenization("hello", 320000)
    print(f"\\nTokenization: {tokenize.to_string()}")
    
    path = capture.capture_agrm_path("A", "D", ["A", "B", "C", "D"])
    print(f"\\nAGRM Path: {path.to_string()}")
    
    dihedral = capture.capture_dihedral_transform(12, 3, False)
    print(f"\\nDihedral: {dihedral.to_string()}")
    
    # Compose all operations
    print("\\n" + "="*70)
    print("[2] Composing all operations...")
    
    composed = capture.get_composed_lambda()
    print(f"\\nComposed lambda: {composed.to_string()}")
    
    # Export log
    capture.export_log(str(Path(__file__).parent / "lambda_operations_log.json"))
    
    # Demonstrate evaluation
    print("\\n" + "="*70)
    print("[3] Evaluating lambda terms...")
    
    evaluator = LambdaE8Evaluator()
    
    # Simple example: (λ x. x) 42
    builder = LambdaE8Builder()
    identity = builder.abs("x", builder.var("x"))
    result = evaluator.evaluate(builder.app(identity, builder.var("42")))
    print(f"\\n(λ x. x) 42 = {result}")
    print(f"Reduction steps: {evaluator.reduction_steps}")
    
    print("\\n" + "="*70)
    print("DEMO COMPLETE")
    print("="*70)


if __name__ == "__main__":
    demo_lambda_e8_calculus()



# ============================================================# MODULE: GeometryTransformerStandaloneV2 (from code_monolith.py)# ============================================================


#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Geometry-Only Transformer — Standalone v2
=========================================
No third-party deps. Pure stdlib. Drop-in script you can run anywhere.

What it is:
  • A geometry-native "transformer" that uses only metric & angular relations
    (no token IDs, no text embeddings, no numpy).
  • Content-addressed, ledgered compute (GeoLight) with an append-only Merkle chain.
  • Channels {3,6,9} and ΔΦ guard hooks to mirror CQE governance lanes.
  • Minimal λ-like "shape program" to generate/transform point clouds.
  • Demos: polygon completion, symmetry inference, curve extrapolation, tiling.

This file is intentionally self-contained. Import nothing except stdlib.

Usage:
  python geometry_transformer_standalone_v2.py --demo all
  python geometry_transformer_standalone_v2.py --demo polygon --n 6 --k 3
"""

import json, time, math, random, argparse, sys, hashlib, os
from dataclasses import dataclass, asdict
from typing import List, Tuple, Dict, Any, Optional, Callable

# ╔══════════════════════════════════════════════════════════════════════╗
# ║                         GeoLight (ledger/cache)                      ║
# ╚══════════════════════════════════════════════════════════════════════╝

def _sha256_hex(b: bytes) -> str:
    return hashlib.sha256(b).hexdigest()

def _now() -> float:
    return time.time()

@dataclass
class LedgerEntry:
    idx: int
    ts: float
    scope: str
    channel: int
    input_hash: str
    result_hash: str
    cost: float
    ttl: Optional[float]
    prev: str
    entry: str

class GeoLight:
    """"""
    def __init__(self, disk_dir: Optional[str]=None, ledger_path: Optional[str]=None, default_ttl: Optional[float]=None):
        self.disk_dir = disk_dir
        self.ledger_path = ledger_path
        self.default_ttl = default_ttl
        self.prev_hash = "0"*64
        self.entries: List[LedgerEntry] = []
        self.mem: Dict[str, Tuple[bytes, Optional[float]]] = {}
        if self.disk_dir:
            os.makedirs(self.disk_dir, exist_ok=True)
        if self.ledger_path:
            os.makedirs(os.path.dirname(self.ledger_path), exist_ok=True)
            open(self.ledger_path, "a").close()

    def _disk_path(self, key: str) -> str:
        return os.path.join(self.disk_dir, key[:2] if self.disk_dir else "", key + ".json") if self.disk_dir else ""

    def compute(self, payload: Dict[str, Any], *, scope: str="geo", channel: int=3,
                compute_fn: Callable[[], Dict[str, Any]], ttl: Optional[float]=None) -> Tuple[Dict[str,Any], float, str]:
        ttl = self.default_ttl if ttl is None else ttl
        js = json.dumps(payload, sort_keys=True, default=str).encode("utf-8")
        key = _sha256_hex(js)

        # in-memory
        hit = self.mem.get(key)
        if hit:
            b, exp = hit
            if exp is None or exp > _now():
                return json.loads(b.decode("utf-8")), 0.0, key
            else:
                self.mem.pop(key, None)

        # on-disk
        if self.disk_dir:
            p = self._disk_path(key)
            if os.path.exists(p):
                try:
                    with open(p, "rb") as f: b = f.read()
                    self.mem[key] = (b, (_now() + ttl) if ttl else None)
                    return json.loads(b.decode("utf-8")), 0.0, key
                except Exception:
                    pass

        # compute
        t0 = _now()
        result = compute_fn()
        cost = _now() - t0
        b = json.dumps(result, sort_keys=True, default=str).encode("utf-8")
        self.mem[key] = (b, (_now() + ttl) if ttl else None)
        if self.disk_dir:
            p = self._disk_path(key)
            os.makedirs(os.path.dirname(p), exist_ok=True)
            with open(p, "wb") as f: f.write(b)

        ih = _sha256_hex(js)
        rh = _sha256_hex(b)
        entry_payload = {"idx": len(self.entries), "ts": _now(), "scope": scope, "channel": channel,
                         "input_hash": ih, "result_hash": rh, "cost": cost, "ttl": ttl, "prev": self.prev_hash}
        entry_hash = _sha256_hex(json.dumps(entry_payload, sort_keys=True).encode("utf-8"))
        le = LedgerEntry(idx=entry_payload["idx"], ts=entry_payload["ts"], scope=scope, channel=channel,
                         input_hash=ih, result_hash=rh, cost=cost, ttl=ttl, prev=self.prev_hash, entry=entry_hash)
        self.entries.append(le)
        self.prev_hash = entry_hash
        if self.ledger_path:
            with open(self.ledger_path, "a", encoding="utf-8") as f:
                f.write(json.dumps(asdict(le)) + "\\n")
        return result, cost, key

    def verify(self) -> bool:
        prev = "0"*64
        for e in self.entries:
            payload = {"idx": e.idx, "ts": e.ts, "scope": e.scope, "channel": e.channel,
                       "input_hash": e.input_hash, "result_hash": e.result_hash,
                       "cost": e.cost, "ttl": e.ttl, "prev": prev}
            h = _sha256_hex(json.dumps(payload, sort_keys=True).encode("utf-8"))
            if h != e.entry: return False
            prev = h
        return True

# ╔══════════════════════════════════════════════════════════════════════╗
# ║                         Geometry core utilities                      ║
# ╚══════════════════════════════════════════════════════════════════════╝

Vec = Tuple[float, float]

def v_add(a: Vec, b: Vec) -> Vec: return (a[0]+b[0], a[1]+b[1])
def v_sub(a: Vec, b: Vec) -> Vec: return (a[0]-b[0], a[1]-b[1])
def v_dot(a: Vec, b: Vec) -> float: return a[0]*b[0] + a[1]*b[1]
def v_norm(a: Vec) -> float: return math.hypot(a[0], a[1])
def v_scale(a: Vec, s: float) -> Vec: return (a[0]*s, a[1]*s)
def v_rot(a: Vec, theta: float) -> Vec:
    c, s = math.cos(theta), math.sin(theta)
    return (a[0]*c - a[1]*s, a[0]*s + a[1]*c)

def centroid(ps: List[Vec]) -> Vec:
    n = max(1, len(ps))
    return (sum(p[0] for p in ps)/n, sum(p[1] for p in ps)/n)

def angle(a: Vec) -> float:
    return math.atan2(a[1], a[0])

def rbf(dist: float, sigma: float) -> float:
    return math.exp(-(dist*dist)/(2*sigma*sigma))

def cos_sim(a: Vec, b: Vec) -> float:
    na, nb = v_norm(a), v_norm(b)
    if na == 0 or nb == 0: return 0.0
    return max(-1.0, min(1.0, v_dot(a,b)/(na*nb)))

# ╔══════════════════════════════════════════════════════════════════════╗
# ║                     Geometry-Only Transformer layer                  ║
# ╚══════════════════════════════════════════════════════════════════════╝

@dataclass
class GeoToken:
    pos: Vec                  # position in plane
    feat: Tuple[float, ...]   # arbitrary small feature vector (e.g., [curvature, tag])
    tag: str = ""             # optional label

class GeoAttention:
    """
    A single "attention" layer using purely geometric relations:
      • Keys/Queries: normalized direction vectors from local centroid
      • Values: token features (+pos residuals)
      • Weights: RBF(dist; sigma) * (1 + cos(angle delta))^alpha
    """
    def __init__(self, sigma: float=0.5, alpha: float=1.0, mix_pos: float=0.5):
        self.sigma = sigma
        self.alpha = alpha
        self.mix_pos = mix_pos

    def forward(self, toks: List[GeoToken]) -> List[GeoToken]:
        if not toks: return []
        pts = [t.pos for t in toks]
        c = centroid(pts)
        dirs = [v_sub(p, c) for p in pts]
        # avoid zero dir by nudging
        dirs = [(d[0]+1e-9, d[1]+1e-9) if v_norm(d)==0 else d for d in dirs]

        out: List[GeoToken] = []
        for i, ti in enumerate(toks):
            qi = dirs[i]
            accf = [0.0]*len(ti.feat)
            accp = (0.0, 0.0)
            z = 0.0
            for j, tj in enumerate(toks):
                if i == j: continue
                dj = dirs[j]
                w = rbf(v_norm(v_sub(ti.pos, tj.pos)), self.sigma) * ((1.0 + cos_sim(qi, dj))**self.alpha)
                z += w
                # value = mix(features, position delta)
                accf = [af + w*fj for af, fj in zip(accf, tj.feat)]
                accp = v_add(accp, v_scale(v_sub(tj.pos, ti.pos), w))
            if z == 0: z = 1.0
            nf = tuple(af/z for af in accf)
            np = v_add(ti.pos, v_scale(accp, self.mix_pos/z))
            # residual update
            out.append(GeoToken(np, tuple((fi + nfi)/2 for fi, nfi in zip(ti.feat, nf)), ti.tag))
        return out

class GeoTransformer:
    """"""
    def __init__(self, layers: int=3, sigma: float=0.5, alpha: float=1.0, mix_pos: float=0.5):
        self.layers = [GeoAttention(sigma, alpha, mix_pos) for _ in range(layers)]
        # Tiny readout parameters (fixed here; could be trainable via gradient-free rules)
        self.w_read = [0.6, 0.4, -0.2, 0.1]  # up to 4-dim feats supported

    def encode(self, pts: List[Vec], tags: Optional[List[str]]=None) -> List[GeoToken]:
        tags = tags or [""]*len(pts)
        c = centroid(pts)
        toks = []
        for p, tg in zip(pts, tags):
            d = v_sub(p, c)
            th = angle(d)
            r = v_norm(d)
            # features = [radius, angle/π, 1] (pad to 4)
            f = [r, th/math.pi, 1.0, 0.0]
            toks.append(GeoToken(p, tuple(f), tg))
        return toks

    def decode_score(self, toks: List[GeoToken]) -> float:
        # Example readout: pooled feature projection to a scalar for classification-ish tasks
        if not toks: return 0.0
        pool = [0.0]*len(toks[0].feat)
        for t in toks:
            pool = [a+b for a,b in zip(pool, t.feat)]
        pool = [x/len(toks) for x in pool]
        w = self.w_read[:len(pool)]
        return sum(a*b for a,b in zip(pool, w))

    def step(self, toks: List[GeoToken]) -> List[GeoToken]:
        for layer in self.layers:
            toks = layer.forward(toks)
        return toks

# ╔══════════════════════════════════════════════════════════════════════╗
# ║                         Shape "λ-programs"                           ║
# ╚══════════════════════════════════════════════════════════════════════╝

def regular_ngon(n: int, r: float=1.0, theta0: float=0.0, center: Vec=(0.0,0.0)) -> List[Vec]:
    return [v_add(center, (r*math.cos(theta0 + 2*math.pi*k/n), r*math.sin(theta0 + 2*math.pi*k/n))) for k in range(n)]

def rotate_shape(pts: List[Vec], theta: float, about: Optional[Vec]=None) -> List[Vec]:
    about = centroid(pts) if about is None else about
    return [v_add(about, v_rot(v_sub(p, about), theta)) for p in pts]

def scale_shape(pts: List[Vec], s: float, about: Optional[Vec]=None) -> List[Vec]:
    about = centroid(pts) if about is None else about
    return [v_add(about, v_scale(v_sub(p, about), s)) for p in pts]

def reflect_shape(pts: List[Vec], axis: Tuple[Vec,Vec]) -> List[Vec]:
    a, b = axis
    ab = v_sub(b,a); abn = v_norm(ab)
    if abn == 0: return pts
    ux, uy = ab[0]/abn, ab[1]/abn
    def refl(p):
        ap = v_sub(p, a)
        proj = (ap[0]*ux + ap[1]*uy)
        pr = (a[0] + proj*ux, a[1] + proj*uy)
        perp = v_sub(p, pr)
        return v_sub(pr, perp)
    return [refl(p) for p in pts]

# ╔══════════════════════════════════════════════════════════════════════╗
# ║                           Demos & tasks                              ║
# ╚══════════════════════════════════════════════════════════════════════╝

def demo_polygon_completion(n=6, k=3, layers=3) -> Dict[str,Any]:
    """"""
    true_pts = regular_ngon(n, r=1.0, theta0=0.0, center=(0.0,0.0))
    known = true_pts[:k]
    gt_rest = true_pts[k:]

    gt = GeoTransformer(layers=layers, sigma=0.6, alpha=1.0, mix_pos=0.7)
    toks = gt.encode(known)
    toks = gt.step(toks)

    # infer rotation angle from mean neighbor delta
    c = centroid([t.pos for t in toks])
    dirs = [v_sub(t.pos, c) for t in toks]
    angs = [angle(d) for d in dirs]
    angs = sorted(angs)
    if len(angs) >= 2:
        # average gap
        gaps = [(angs[(i+1)%len(angs)] - angs[i])%(2*math.pi) for i in range(len(angs))]
        dtheta = sum(gaps)/len(gaps)
    else:
        dtheta = 2*math.pi/n

    # propose remaining pts
    last = known[-1]
    rem = []
    for _ in range(n-k):
        v = v_sub(last, c)
        v = v_rot(v, dtheta)
        nxt = v_add(c, v)
        rem.append(nxt)
        last = nxt

    score = gt.decode_score(toks)
    return {"known": known, "pred_rest": rem, "gt_rest": gt_rest, "score": score, "n": n, "k": k, "dtheta": dtheta}

def demo_symmetry_inference(layers=3) -> Dict[str,Any]:
    """"""
    pts = regular_ngon(n=random.choice([3,4,5,6,8]), r=1.0, theta0=random.random()*2*math.pi)
    pts = scale_shape(rotate_shape(pts, 0.17), 1.0 + 0.05*random.random())
    gt = GeoTransformer(layers=layers, sigma=0.5, alpha=1.3, mix_pos=0.5)
    toks = gt.step(gt.encode(pts))
    c = centroid([t.pos for t in toks])
    angs = [((angle(v_sub(p,c))%(2*math.pi))) for p in pts]
    angs.sort()
    gaps = [((angs[(i+1)%len(angs)]-angs[i])%(2*math.pi)) for i in range(len(angs))]
    mean_gap = sum(gaps)/len(gaps)
    order = max(3, int(round((2*math.pi)/mean_gap)))
    return {"pts": pts, "order": order, "mean_gap": mean_gap}

def demo_curve_extrapolation(m=12, layers=3) -> Dict[str,Any]:
    """"""
    xs = [i*0.3 for i in range(m)]
    ys = [math.sin(x) for x in xs]
    pts = list(zip(xs, ys))
    known = pts[:m-3]
    gt = GeoTransformer(layers=layers, sigma=0.8, alpha=1.0, mix_pos=0.4)
    toks = gt.step(gt.encode(known))
    # Extrapolate using last chord and average curvature estimated geometrically
    p1, p2, p3 = known[-3], known[-2], known[-1]
    v1, v2 = v_sub(p2,p1), v_sub(p3,p2)
    ang = (angle(v2)-angle(v1))
    # normalize angle to [-pi,pi]
    if ang > math.pi: ang -= 2*math.pi
    if ang < -math.pi: ang += 2*math.pi
    step = v_norm(v2)
    pred1 = v_add(p3, v_rot(v2, ang))
    pred2 = v_add(pred1, v_rot(v2, ang))
    return {"known": known, "pred": [pred1, pred2], "gt_next": pts[m-2:], "est_turn": ang, "step": step}

def demo_tiling_hex(radius=2, layers=2) -> Dict[str,Any]:
    """"""
    base = regular_ngon(6, r=1.0)
    tiles = []
    for i in range(-radius, radius+1):
        for j in range(-radius, radius+1):
            shift = (i*1.5, j*math.sqrt(3)/2 + (i%2)*math.sqrt(3)/4)
            tiles.extend([v_add(p, shift) for p in base])
    gt = GeoTransformer(layers=layers, sigma=0.9, alpha=1.0, mix_pos=0.3)
    toks = gt.step(gt.encode(tiles))
    score = gt.decode_score(toks)
    return {"tiles": tiles, "score": score, "count": len(tiles)}

# ╔══════════════════════════════════════════════════════════════════════╗
# ║                         ΔΦ guard & channels                          ║
# ╚══════════════════════════════════════════════════════════════════════╝

def delta_phi(before: List[GeoToken], after: List[GeoToken]) -> float:
    """"""
    if len(before) != len(after): return float("inf")
    s = 0.0
    for b,a in zip(before, after):
        dp = v_sub(a.pos, b.pos)
        s += v_dot(dp, dp)
        s += sum((af-bf)*(af-bf) for af,bf in zip(a.feat, b.feat))
    return s

def channel_policy(channel: int, dphi: float) -> bool:
    # Example policy: channel 3 allows small positive ΔΦ, 6 enforces ΔΦ≤0.1, 9 prefers exactly 0 (idempotent)
    if channel == 3: return dphi <= 1e3
    if channel == 6: return dphi <= 0.1
    if channel == 9: return dphi <= 1e-6
    return True

# ╔══════════════════════════════════════════════════════════════════════╗
# ║                             CLI & Runner                             ║
# ╚══════════════════════════════════════════════════════════════════════╝

def run_with_ledger(payload: Dict[str, Any], compute: Callable[[], Dict[str,Any]],
                    scope="geom-xf", channel=3, ttl=30.0, use_disk=False):
    gl = GeoLight(disk_dir=".geolight/cache" if use_disk else None,
                  ledger_path=".geolight/ledger.jsonl" if use_disk else None,
                  default_ttl=ttl)
    res, cost, rid = gl.compute(payload, scope=scope, channel=channel, compute_fn=compute, ttl=ttl)
    return {"result": res, "cost": cost, "receipt": rid, "ledger_ok": gl.verify(), "entries": len(gl.entries)}

def main(argv=None):
    p = argparse.ArgumentParser()
    p.add_argument("--demo", type=str, default="all", choices=["all","polygon","symmetry","curve","tiling"])
    p.add_argument("--n", type=int, default=6, help="polygon sides")
    p.add_argument("--k", type=int, default=3, help="known vertices for polygon")
    p.add_argument("--layers", type=int, default=3)
    p.add_argument("--channel", type=int, default=3, choices=[3,6,9])
    p.add_argument("--disk", action="store_true")
    args = p.parse_args(argv)

    if args.demo in ("all","polygon"):
        payload = {"demo":"polygon","n":args.n,"k":args.k,"layers":args.layers}
        def compute(): return demo_polygon_completion(n=args.n, k=args.k, layers=args.layers)
        out = run_with_ledger(payload, compute, channel=args.channel, use_disk=args.disk)
        print("POLYGON:", json.dumps(out, indent=2))

    if args.demo in ("all","symmetry"):
        payload = {"demo":"symmetry","layers":args.layers}
        def compute(): return demo_symmetry_inference(layers=args.layers)
        out = run_with_ledger(payload, compute, channel=args.channel, use_disk=args.disk)
        print("SYMMETRY:", json.dumps(out, indent=2))

    if args.demo in ("all","curve"):
        payload = {"demo":"curve","layers":args.layers}
        def compute(): return demo_curve_extrapolation(layers=args.layers)
        out = run_with_ledger(payload, compute, channel=args.channel, use_disk=args.disk)
        print("CURVE:", json.dumps(out, indent=2))

    if args.demo in ("all","tiling"):
        payload = {"demo":"tiling","layers":args.layers}
        def compute(): return demo_tiling_hex(layers=args.layers)
        out = run_with_ledger(payload, compute, channel=args.channel, use_disk=args.disk)
        print("TILING:", json.dumps(out, indent=2))

if __name__ == "__main__":
    main()


# ============================================================# MODULE: LatticeViewer (from code_monolith.py)# ============================================================

